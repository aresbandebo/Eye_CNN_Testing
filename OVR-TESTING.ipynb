{
 "cells": [
  {
   "cell_type": "code",
   "id": "74c5398ef0d8c133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:06:40.811645Z",
     "start_time": "2025-10-26T14:06:37.646321Z"
    }
   },
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# --- Constants and Configuration ---\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "DATA_DIR = '/Users/aresbandebo/PycharmProjects/Eye_CNN_Testing/Dataset_Eye_Diseases_Classification/'\n",
    "CLASS_NAMES = ['cataract', 'conjunctivitis', 'eyelid', 'normal', 'uveitis']"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# OLD Step 2: Load and Preprocess the Data\n",
    "def load_data(data_dir, class_names, img_width, img_height):\n",
    "    images = []\n",
    "    labels = []\n",
    "    print(\"Loading image data...\")\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "                img = cv2.resize(img, (img_width, img_height))\n",
    "                images.append(img)\n",
    "                labels.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    print(\"Image data loaded successfully.\")\n",
    "    return np.array(images), np.array(labels)\n"
   ],
   "id": "3cb74aba46a3e33c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:08:38.184003Z",
     "start_time": "2025-10-26T14:08:37.024830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# NEW Step 2: Load and Preprocess the Data\n",
    "def load_data(data_dir, class_names, img_width, img_height):\n",
    "    images = []\n",
    "    labels = []\n",
    "    print(\"Loading image data...\")\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                img = cv2.imread(img_path)\n",
    "\n",
    "                # --- THIS IS THE FIX ---\n",
    "                # Convert from BGR (OpenCV) to RGB (Matplotlib)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                # --- END OF FIX ---\n",
    "\n",
    "                img = cv2.resize(img, (img_width, img_height))\n",
    "                images.append(img)\n",
    "                labels.append(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_path}: {e}\")\n",
    "    print(\"Image data loaded successfully.\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the initial data\n",
    "images, labels = load_data(DATA_DIR, CLASS_NAMES, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "# Normalize pixel values\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# --- Model Definition ---\n",
    "def create_ovr_model(input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)):\n",
    "    \"\"\"Creates a binary classifier based on EfficientNetB0 for OvR.\"\"\"\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(name=\"avg_pool\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3, name=\"top_dropout\"),\n",
    "        # Final layer for binary classification (One-vs-Rest)\n",
    "        layers.Dense(1, activation='sigmoid', name=\"pred\")\n",
    "    ])\n",
    "    return model"
   ],
   "id": "ccebb0430f8b8d32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image data...\n",
      "Image data loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# OLD Step 4: Display sample images\n",
    "def show_sample_images(sample_images, sample_labels, class_names_map):\n",
    "    plt.figure(figsize=(12, 120))\n",
    "    for i in range(min(30, len(sample_images))): # Show up to 240 images\n",
    "        plt.subplot(60, 4, i + 1)\n",
    "        plt.imshow(sample_images[i])\n",
    "        # Convert one-hot encoded label back to integer, then to class name\n",
    "        label_index = sample_labels[i]\n",
    "        plt.title(class_names_map[label_index])\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(\"Sample Images from Training Set\", fontsize=16, y=0.9)\n",
    "    plt.show()\n",
    "\n",
    "# Display some images from the training set to verify\n"
   ],
   "id": "621c05854fee93f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T14:09:10.986809Z",
     "start_time": "2025-10-26T14:09:10.984002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 4: Display sample images\n",
    "def show_sample_images(sample_images, sample_labels, class_names_map):\n",
    "    plt.figure(figsize=(12, 120))\n",
    "    for i in range(min(30, len(sample_images))): # Show up to 240 images\n",
    "        plt.subplot(60, 4, i + 1)\n",
    "        plt.imshow(sample_images[i])\n",
    "\n",
    "        # --- START OF FIX ---\n",
    "        label_value = sample_labels[i]\n",
    "\n",
    "        # Check if the label is an integer (like 0, 1) or a string (like 'cataract')\n",
    "        if isinstance(label_value, (int, np.integer)):\n",
    "            # If it's an integer, use it as an index to look up the name\n",
    "            plt.title(class_names_map[label_value])\n",
    "        else:\n",
    "            # If it's already a string, just use it directly\n",
    "            plt.title(label_value)\n",
    "        # --- END OF FIX ---\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(\"Sample Images from Training Set\", fontsize=16, y=0.9)\n",
    "    plt.show()"
   ],
   "id": "d34eeab87dc33d82",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# OLD--- One-vs-Rest (OvR) Training Loop ---\n",
    "# This loop will train a separate binary classifier for each class.\n",
    "\n",
    "for class_name in CLASS_NAMES[0:1]:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"    Training Model for: {class_name} vs. Rest\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 1. Create Binary Labels for the current class\n",
    "    # The \"positive\" class is labeled 1, all others are 0.\n",
    "    print(f\"Preparing binary labels for '{class_name}'...\")\n",
    "    binary_labels = np.array([1 if label == class_name else 0 for label in labels])\n",
    "\n",
    "    # 2. Split the Data for the current binary classification task\n",
    "    # We stratify to ensure the train/val/test sets have a similar proportion of positive/negative samples.\n",
    "    (X_train_temp, X_test, y_train_temp, y_test) = train_test_split(\n",
    "        images, binary_labels, test_size=0.20, stratify=binary_labels, random_state=42\n",
    "    )\n",
    "    (X_train, X_val, y_train, y_val) = train_test_split(\n",
    "        X_train_temp, y_train_temp, test_size=0.25, stratify=y_train_temp, random_state=42 # 0.25 * 0.8 = 0.2\n",
    "    )\n",
    "    print(f\"Data split complete for '{class_name}'.\")\n",
    "    print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}, Testing samples: {len(X_test)}\")\n",
    "\n",
    "show_sample_images(images, labels, CLASS_NAMES)\n",
    "    # 3. Create and Compile the Model\n",
    "    # We use 'binary_crossentropy' for the loss function.\n",
    "    ovr_model = create_ovr_model()\n",
    "    ovr_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(f\"Model for '{class_name}' compiled successfully.\")\n",
    "\n",
    "    # 4. Train the Model\n",
    "    print(f\"Starting training for '{class_name}' for {EPOCHS} epochs...\")\n",
    "    start_time = time.time()\n",
    "    history = ovr_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=2 # Set to 2 for less output per epoch\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Training for '{class_name}' finished in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    # 5. Save the Trained Model\n",
    "    # Each model is saved with a unique name.\n",
    "    model_filename = f\"efficientnet_ovr_{class_name}.h5\"\n",
    "    ovr_model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    # 6. Evaluate the Model on the Test Set\n",
    "    test_loss, test_acc = ovr_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy for {class_name} vs. Rest: {test_acc:.2%}\")\n",
    "    print(f\"Test Loss for {class_name} vs. Rest: {test_loss:.4f}\")\n",
    "    print(\"\\nDisplaying a sample of training images...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All One-vs-Rest models have been trained successfully!\")\n",
    "print(\"=\"*50 + \"\\n\")"
   ],
   "id": "eb65e16c4686f03a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "print(CLASS_NAMES)\n",
    "show_sample_images(X_train, y_train, [\"target\", \"other\"])\n"
   ],
   "id": "2636e3f200a5957c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NEW--- One-vs-Rest (OvR) Training Loop ---\n",
    "# This version includes class weights to handle data imbalance and a two-stage fine-tuning process.\n",
    "\n",
    "INITIAL_EPOCHS = 10\n",
    "FINE_TUNE_EPOCHS = 10\n",
    "TOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"    Training Model for: {class_name} vs. Rest\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 1. Create Binary Labels\n",
    "    binary_labels = np.array([1 if label == class_name else 0 for label in labels])\n",
    "\n",
    "    # 2. Split the Data\n",
    "    (X_train_temp, X_test, y_train_temp, y_test) = train_test_split(\n",
    "        images, binary_labels, test_size=0.20, stratify=binary_labels, random_state=42\n",
    "    )\n",
    "    (X_train, X_val, y_train, y_val) = train_test_split(\n",
    "        X_train_temp, y_train_temp, test_size=0.25, stratify=y_train_temp, random_state=42\n",
    "    )\n",
    "    print(f\"Data split complete for '{class_name}'.\")\n",
    "\n",
    "    # --- THE FIX: CALCULATE CLASS WEIGHTS ---\n",
    "    # This balances the loss function, forcing the model to pay attention to the minority class.\n",
    "    weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight = {0: weights[0], 1: weights[1]}\n",
    "    print(f\"Class weights for '{class_name}': {class_weight}\")\n",
    "\n",
    "    # 3. Create and Compile the Model for Stage 1\n",
    "    ovr_model = create_ovr_model()\n",
    "    ovr_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # --- Stage 1: Initial Training (with Class Weights) ---\n",
    "    print(\"\\n--- Starting Stage 1: Initial Training ---\")\n",
    "    history = ovr_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=INITIAL_EPOCHS,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_weight=class_weight,  # <--- Apply the class weights here\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # --- Stage 2: Fine-Tuning ---\n",
    "    print(\"\\n--- Starting Stage 2: Fine-Tuning ---\")\n",
    "    ovr_model.layers[0].trainable = True # Unfreeze the base model\n",
    "\n",
    "    # Unfreeze the top 30 layers for fine-tuning\n",
    "    for layer in ovr_model.layers[0].layers[:-30]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Re-compile with a very low learning rate for fine-tuning\n",
    "    ovr_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Continue training (fine-tuning)\n",
    "    history_fine = ovr_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=TOTAL_EPOCHS,\n",
    "        initial_epoch=history.epoch[-1],\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_weight=class_weight, # <--- Also apply weights during fine-tuning\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # 4. Save and Evaluate the Final Model\n",
    "    model_filename = f\"efficientnet_ovr_{class_name}_finetuned.h5\"\n",
    "    ovr_model.save(model_filename)\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "\n",
    "    test_loss, test_acc = ovr_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"\\nFinal Test Accuracy for {class_name} vs. Rest: {test_acc:.2%}\")\n",
    "\n",
    "print(\"\\nAll models have been trained and fine-tuned successfully!\")"
   ],
   "id": "f4b33d99aefeb48f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Inference Section: Making a Prediction on a New Image ---\n",
    "\n",
    "def predict_image_ovr(image_path, model_dir='.'):\n",
    "    \"\"\"\n",
    "    Loads a new image, preprocesses it, and predicts its class\n",
    "    using the saved One-vs-Rest models.\n",
    "    \"\"\"\n",
    "    # 1. Load the trained OvR models\n",
    "    ovr_models = {}\n",
    "    for class_name in CLASS_NAMES:\n",
    "        model_path = os.path.join(model_dir, f\"efficientnet_ovr_{class_name}.h5\")\n",
    "        if os.path.exists(model_path):\n",
    "            ovr_models[class_name] = tf.keras.models.load_model(model_path)\n",
    "        else:\n",
    "            print(f\"Warning: Model not found for class '{class_name}' at {model_path}\")\n",
    "            return\n",
    "\n",
    "    # 2. Load and preprocess the new image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    img_array = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    img_array = img_array.astype('float32') / 255.0\n",
    "\n",
    "    # 3. Get a prediction score from each binary classifier\n",
    "    scores = {}\n",
    "    for class_name, model in ovr_models.items():\n",
    "        score = model.predict(img_array)[0][0]\n",
    "        scores[class_name] = score\n",
    "\n",
    "    # 4. Determine the final prediction\n",
    "    # The class with the highest probability score is the winner.\n",
    "    predicted_class = max(scores, key=scores.get)\n",
    "    highest_score = scores[predicted_class]\n",
    "\n",
    "    print(\"\\n--- Prediction Results ---\")\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"Predicted Condition: {predicted_class.capitalize()}\")\n",
    "    print(f\"Confidence Score: {highest_score:.2%}\")\n",
    "    print(\"\\n--- Individual Model Scores ---\")\n",
    "    for class_name, score in sorted(scores.items(), key=lambda item: item[1], reverse=True):\n",
    "        print(f\"- {class_name.capitalize()}: {score:.2%}\")\n",
    "\n",
    "# Example of how to use the prediction function\n",
    "# Make sure you have an image to test with, for example 'test_image.jpg'\n",
    "predict_image_ovr('/Users/aresbandebo/PycharmProjects/Eye_CNN_Testing/Dataset_Eye_Diseases_Classification/img_1.png')"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
